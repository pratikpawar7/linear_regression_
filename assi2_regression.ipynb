{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694650a-7d66-4c86-900b-7a7076e9321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. 
 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8bfc54-bb1a-402f-8d0d-195c19eb6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "represent?\n",
    "'''\n",
    "R-squared is the number that shows how well a data fit linear regression model. \n",
    "It tells the how much variation in the dependent variable is  explained by the independent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66677d-e1d4-432a-82c1-fcc04f89064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "'''\n",
    "Adjusted R-squared is a version of R-squared that adjusts for the number of predictors in a model.\n",
    "It considers the degrees of freedom, preventing overestimation of the model performance. \n",
    "Unlike regular R-squared, which always increases with more predictors, \n",
    "adjusted R-squared can decrease if new predictors donot improve the model significantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d680c-a6da-4df2-a4a2-d36f72c64d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3. When is it more appropriate to use adjusted R-squared?\n",
    "'''\n",
    "It is more appropriate to use adjusted R-squared when comparing regression models with \n",
    "different numbers of predictors. Adjusted R-squared accounts for the complexity of the model,\n",
    "ensuring you donot get a falsely high R-squared just by adding more predictors. \n",
    "This helps in choosing the model that best balances goodness of fit and simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb136cb7-d11f-45e1-9e26-1c0a6dc4528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4. what are RMSE  , MSE , MAE in the context of regression analysis.? how are this matrics \n",
    "calculated and what do they represent ? \n",
    "'''\n",
    "RMSE , MSE , MAE are the metrics to evaluate the performance of regression model . \n",
    "\n",
    "MSE: Measures the average squared difference between actual and predicted values.\n",
    "    It is calculated as the average of the squared errors.\n",
    "    \n",
    "RMSE: The square root of MSE. It provides the error in the same units as the original data.\n",
    "\n",
    "MAE: Measures the average absolute difference between actual and predicted values.\n",
    "     It is calculated as the average of the absolute errors.\n",
    "    \n",
    "    THis matrics represent accuracy of the model , lower the value it is good fot accuracy. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed350a-f849-4af7-8941-4d4780a420b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis.\n",
    "'''\n",
    "\n",
    "RMSE:\n",
    "Advantages: Provides error in the same units as the original data; sensitive to large errors.\n",
    "Disadvantages: Can be heavily influenced by outliers due to squaring errors.\n",
    "\n",
    "MSE:\n",
    "Advantages: Easy to compute; penalizes larger errors more than smaller ones.\n",
    "Disadvantages: Like RMSE, it is sensitive to outliers; not in the same units as the original data.\n",
    "\n",
    "MAE:\n",
    "Advantages: Less sensitive to outliers; provides a clear interpretation of the average error.\n",
    "Disadvantages: Does not penalize large errors as much as RMSE/MSE; less sensitive to variations in the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86b712-be19-49f1-b444-d1c31b03f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?\n",
    "'''\n",
    "\n",
    "Lasso Regularization adds a penalty equal to the absolute value of the coefficients to the loss function.\n",
    "This encourages sparsity, meaning it can shrink some coefficients to exactly zero\n",
    "\n",
    "Difference from Ridge Regularization:\n",
    "\n",
    "Ridge adds a penalty equal to the square of the coefficients, which shrinks coefficients but doesn't set them to zero.\n",
    "Lasso can produce sparse models with fewer predictors, while Ridge typically keeps all predictors.\n",
    "When to use Lasso:\n",
    "\n",
    "Use Lasso : when you suspect that only a few predictors are important. It is useful for \n",
    "            feature selection and creating simpler models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84269ed-a0ae-4a43-bd99-14905d026a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate.\n",
    "'''\n",
    "\n",
    "\n",
    "Regularized linear models, like Lasso and Ridge, add penalties to the loss function to prevent\n",
    "overfitting by discouraging overly complex models.\n",
    "This helps the model generalize better to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b75210-1bed-4038-b375-5375fbbfab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis.\n",
    "'''\n",
    "Limitations of Regularized Linear Models:\n",
    "\n",
    "Interpretability: Harder to interpret with many predictors shrunk or set to zero.\n",
    "Feature Selection: Lasso might arbitrarily pick one from correlated predictors.\n",
    "Model Assumptions: Assumes a linear relationship, which may not fit complex data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95354e-7f63-4c65-9e04-403e1869636f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
